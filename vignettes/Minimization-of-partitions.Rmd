---
title: "Minimization of partitions"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Minimization of partitions}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

```{r setup, message = F}
library(QCAcluster)
library(formattable) # nicer html tables
```

Two functions allow empirical researchers to partition clustered data on one or two dimensions and to derive solutions for the pooled data and for each partition. `partition_min()` is available for producing conservative or parsimonious solutions. `partition_min_inter()` has to be used for the intermediate solution. (For programming purposes, we opted for separate functions for the intermediate solution and the other two.)

## Panel data: Minimization for cross sections and time series
We first illustrate how one can dempose panel data on two dimensions. In a *between-unit* perspective, the panel is partitioned into multiple cross sections with the `time` argument that specifies the cross section ID (here: years). In a *within-unit* perspective, the data is decomposed into multiple time series with the `units` argument that specifies the time series ID (here: countries). In short, the other parameters are:

- `n_cut`: Frequency threshold for pooled data
- `incl_cut`: Inclusion threshold (a.k.a. consistency threshold) for pooled data
- `solution`: Either `C` for conservative solution (a.k.a. complex solution) or `P` for parsimonious solution
- `BE_cons` and `WI_cons`: Inclusion thresholds for the cross sections and time series. The length of the numeric vector should equal the number of units and time series.
- `BE_ncut` and `WI_ncut`: Frequency thresholds for the cross sections and time series. The length of the numeric vector should equal the number of units and time series.

### Conservative or parsimonious solution
We first illustrate the parsimonious solution with dataset from [Thiem (2011)](https://doi.org/10.1017/S1755773910000251).
```{r}
# loading panel data (see data description for emails)
data(Thiem2011)
# partitioning data by countries (within-unit) and years (between-unit)
Thiem_pars <- partition_min(
  dataset = Thiem2011,
  units = "country", time = "year",
  cond = c("fedismfs", "homogtyfs", "powdifffs", "comptvnsfs", "pubsupfs", "ecodpcefs"),
  out = "memberfs",
  n_cut = 6, incl_cut = 0.8,
  solution = "P",
  BE_cons = c(0.9, 0.8, 0.7, 0.8, 0.85, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8),
  BE_ncut = rep(1, 11),
  WI_cons = c(0.75, 0.8, 0.9, 0.8, 0.85, rep(0.75, 10)),
  WI_ncut = rep(1, 15))
formattable(Thiem_pars)
```

The output of `partition_min()` is a dataframe summarizing the solutions for the pooled data and the partitions and the consistency and coverage values for the solution. There are different reasons why one might not be able to derive a partition-specific solution: All rows could be consistent; all rows could be inconsistent; there is no variation and all cases belong to the same truth table row. If one the reason applies, it is specifically listed in the column `solution`.

The function produces the information than one sees in the dataframe. It can serve as a basis for spotting interesting insights such as partitions with no variation in conditions that can be explored further in a manual analysis of the data.

### Intermediate solution
The intermediate solution is derived with `partition_min_inter()`. (We decided to have a separate function for the intermediate solution for computational purposes.) For the intermediate solution, one has to specify the directional expectations. 
```{r, error = T}
data(Schwarz2016)
Schwarz_inter_1 <- partition_min_inter(
  Schwarz2016, 
  units = "country", time = "year", 
  cond = c("poltrans", "ecotrans", "reform", "conflict", "attention"), 
  out = "enlarge", 
  n_cut = 1, incl_cut = 0.8, 
  intermediate = c("1", "1", "1", "1", "1"))
```

## Multilevel data
Clustered data can be partitioned on a single dimension if the second dimension is not of interest or if there is only one dimension such as an in multilevel data where lower-level units are nested in higher-level units. We use the dataset by [Grauvogel and von Soest (2014)](https://doi.org/10.1017/S1755773910000251) for illustrating the analysis of multilevel data. The study analyzes the effect of sanctions on authoritarian regimes. The data distinguishes between the source of the sanction (`Sender`) and the target country (`Target). All sanctions have been imposed by the EU, UN or US, which means that target countries are nested in three different senders. We partition the data on the dimension of senders to see how solutions differ across senders.

```{r, error = T}
# loading multilevel data (see data description for emails)
data(Grauvogel2014)
# partitioning data by sender country (higher-level unit)
GS_pars <- partition_min(
  dataset = Grauvogel2014,
  units = "Sender",
  cond = c("Comprehensiveness", "Linkage", "Vulnerability","Repression", "Claims"),
  out = "Persistence",
  n_cut = 1, incl_cut = 0.75,
  solution = "P",
  BE_cons = rep(0.75, 3),
  BE_ncut = rep(1, 3))
formattable(GS_pars)
```

